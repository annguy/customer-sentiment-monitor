{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about visualization of the weekly analysis. In addition, XGBoost and RandomForest have the visualization of the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib, sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('..')\n",
    "from src.train_Ensemble import filter_by_feature_type\n",
    "from src.visualize import plot_recall_at_k, plot_feature_importances, convert_clf_dict_to_df, \\\n",
    "                                          extract_base_clf_probs, calculate_recalls_at_k, plot_weekly_analysis, \\\n",
    "                                          extract_feature_importances, aggregate_feature_importances, \\\n",
    "                                          plot_aggregated_over_weeks, calculate_weight_ratio, plot_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "result_path = 'data/results/'\n",
    "file_name = 'results.pickle'\n",
    "with open(result_path+file_name, 'rb') as f:\n",
    "        classifier_dict = pickle.load(f)\n",
    "# Get config from classifier_dict\n",
    "config = classifier_dict[min(classifier_dict.keys())]['config']\n",
    "# Load feature matrix\n",
    "feature_matrix_path = 'data/processed/' if config['model_name'] == 'LSTM' else 'data/raw/'\n",
    "if config['model_name'] == 'LSTM':\n",
    "    feature_matrix_path, feature_matrix_file_name = 'data/processed/', 'feature_matrix_prep.pickle'\n",
    "else:\n",
    "    feature_matrix_path, feature_matrix_file_name = 'data/raw/', 'feature_matrix.pickle'\n",
    "with open(feature_matrix_path+feature_matrix_file_name, 'rb') as f:\n",
    "    feature_matrix = pickle.load(f)\n",
    "# Path use to save visualizations\n",
    "path = 'data/visualizations/'\n",
    "# Preprocess feature matrix\n",
    "if config['model_name'] != 'LSTM':\n",
    "    feature_matrix = filter_by_feature_type(feature_matrix, feature_type=config['feature_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classifier_dict to DataFrame\n",
    "metrics = ['y_test', 'y_prob', 'confusion_matrix', 'info', 'model']\n",
    "df_data = convert_clf_dict_to_df(classifier_dict, feature_matrix, metrics, config)\n",
    "# Extract probabilities for base classifiers in case of late fusion\n",
    "if config['late_fusion_flag'] and config['model_name'] != 'LSTM':\n",
    "    df_data = extract_base_clf_probs(df_data)\n",
    "# Calculate recalls\n",
    "recalls, num_of_samples, list_k = calculate_recalls_at_k(df_data, k_max=150)\n",
    "# Plot recall at k\n",
    "plot_recall_at_k(recalls, list_k, num_of_samples, int(df_data['# of escalation flags'].sum()), \n",
    "                 title=\"Recall at k\", path=path)\n",
    "# Plot ratio\n",
    "if config['late_fusion_flag'] and config['model_name'] != 'LSTM':\n",
    "    plot_ratio(df_data, path)\n",
    "#PLot weekly analysis\n",
    "for k in [5, 10, 20, 50, 100]:\n",
    "    plot_weekly_analysis(df_data, \"Weekly Analysis\", k, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['model_name'] != 'LSTM':\n",
    "    # Extract feature importances from classifier\n",
    "    # feature_importances (num_weeks, num_feat)\n",
    "    feature_importances = extract_feature_importances(df_data, feature_matrix, classifier_dict, config)\n",
    "    # Aggregate\n",
    "    # feature_importances_over_weeks (num_feat per week, num_weeks)\n",
    "    feature_importances_over_weeks = aggregate_feature_importances(feature_importances, feature_matrix)\n",
    "    # Calculate features and unique features\n",
    "    list_not_feat_cols = ['pred_time', 'escalation_flag', 'customer']\n",
    "    # features (num_features)\n",
    "    features = feature_matrix.drop(columns=list_not_feat_cols).columns\n",
    "    # uniq_features (num_feat per week)\n",
    "    uniq_features = np.unique([feat[:-5] for feat in features])\n",
    "    # feature_importances_over_feat (num_feat)\n",
    "    feature_importances_over_feat = np.mean(feature_importances, axis=0)\n",
    "    # Plot feature importances over features (num_feat)\n",
    "    plot_feature_importances(feature_importances_over_feat, features, \n",
    "                             title='Feature importances aggregated over types | Mean', path=path)\n",
    "    # Plot aggregated features over weeks\n",
    "    plot_aggregated_over_weeks(df_data, feature_importances_over_weeks, uniq_features, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gpu_2",
   "language": "python",
   "name": "test_gpu_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
